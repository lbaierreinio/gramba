In this folder we implemented different types of linear attention mechanisms.

## Linear Self Attention
The linformer is implemented in a python package availible [here](https://github.com/tatp22/linformer-pytorch). It can be downloaded using the following command:

```pip install linformer-pytorch```

It comes from the paper [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/pdf/2006.04768)

An exemple of how to use it is given in the file `linformer.py`.